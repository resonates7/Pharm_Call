{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c564bc-70a4-466e-82c4-8d7deec94f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download transcripts: https://cloud.google.com/storage/docs/gsutil_install\n",
    "!gsutil -m cp -R gs://redacted_transcript_landing/ /Users/tejomay.gadgil/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e475f25c-9a97-49b0-b126-781b3f74a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce017b43-027a-44fb-a89e-2ca082659900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def SDI_redact(input_string):\n",
    "    '''\n",
    "    Purpose of code: Further redactions of transcript on top of GCP redaction.\n",
    "    What the code does: Use regex to strip out months, states, numbers, common first names, and NATO phonetic alphabet.\n",
    "    '''\n",
    "    try:\n",
    "        import re\n",
    "        # months\n",
    "        months = 'January|February|March|April|June|July|August|September|October|November|December' # removed May\n",
    "        input_string = re.sub(months,'[SDI_Redacted_months]', input_string,flags=re.IGNORECASE)\n",
    "        # states\n",
    "        states = 'Alaska|Arizona|Arkansas|California|Colorado|Connecticut|Delaware|\\\n",
    "            Florida|Georgia|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|\\\n",
    "            Maine|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|\\\n",
    "            Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|New York|North Carolina|North Dakota|\\\n",
    "            Ohio|Oklahoma|Oregon|Pennsylvania|Rhode Island|South Carolina|South Dakota|Tennessee|\\\n",
    "            Texas|Utah|Vermont|Virginia|Washington|West Virginia|Wisconsin|Wyoming'\n",
    "        input_string = re.sub(states,'[SDI_Redacted_states]', input_string, flags=re.IGNORECASE)\n",
    "        # numbers\n",
    "        pattern = r\"([0-9]+( , [0-9]+)+)|([0-9]+(,[0-9]+)+)|(\\d+:\\d+)|(\\d+/\\d+)|(\\d+-\\d+)|(\\d+)\"\n",
    "        input_string = re.sub(pattern, r'[SDI_Redacted_numbers]', input_string, flags=re.IGNORECASE)\n",
    "        # phonetic numbers\n",
    "        ph_num = 'zero|two|three|four|five|six|seven|eight|nine'\n",
    "        input_string = re.sub(ph_num,'[SDI_Redacted_ph_numbers]', input_string, flags=re.IGNORECASE)\n",
    "        # first names\n",
    "        names = 'James|Robert|John|Michael|David|William|Richard|Joseph|Thomas|Charles|Christopher|Daniel|Matthew|Anthony|Mark|\\\n",
    "            Donald|Steven|Paul|Andrew|Joshua|Kenneth|Kevin|Brian|George|Timothy|Ronald|Edward|Jason|Jeffrey|Ryan|Jacob|Gary|Nicholas|\\\n",
    "            Eric|Jonathan|Stephen|Larry|Justin|Scott|Brandon|Benjamin|Samuel|Gregory|Alexander|Frank|Patrick|Raymond|Jack|Dennis|Jerry|\\\n",
    "            Tyler|Aaron|Jose|Adam|Nathan|Henry|Douglas|Zachary|Peter|Kyle|Ethan|Walter|Noah|Jeremy|Christian|Keith|Roger|Terry|Gerald|\\\n",
    "            Harold|Sean|Austin|Carl|Arthur|Lawrence|Dylan|Jesse|Jordan|Bryan|Billy|Joe|Bruce|Gabriel|Logan|Albert|Willie|Alan|Juan|Wayne|\\\n",
    "            Elijah|Randy|Roy|Vincent|Ralph|Eugene|Russell|Bobby|Mason|Philip|Louis|Mary|Patricia|Jennifer|Linda|Elizabeth|Barbara|Susan|\\\n",
    "            Jessica|Sarah|Karen|Lisa|Nancy|Betty|Margaret|Sandra|Ashley|Kimberly|Emily|Donna|Michelle|Carol|Amanda|Dorothy|Melissa|Deborah|\\\n",
    "            Stephanie|Rebecca|Sharon|Laura|Cynthia|Kathleen|Amy|Angela|Shirley|Anna|Brenda|Pamela|Emma|Nicole|Helen|Samantha|Katherine|\\\n",
    "            Christine|Debra|Rachel|Carolyn|Janet|Catherine|Maria|Heather|Diane|Ruth|Julie|Olivia|Joyce|Virginia|Victoria|Kelly|Lauren|\\\n",
    "            Christina|Joan|Evelyn|Judith|Megan|Andrea|Cheryl|Hannah|Jacqueline|Martha|Gloria|Teresa|Ann|Sara|Madison|Frances|Kathryn|\\\n",
    "            Janice|Jean|Abigail|Alice|Julia|Judy|Sophia|Grace|Denise|Amber|Doris|Marilyn|Danielle|Beverly|Isabella|Theresa|Diana|Natalie|\\\n",
    "            Brittany|Charlotte|Marie|Kayla|Alexis|Olivia'\n",
    "        input_string = re.sub(names,'[SDI_Redacted_names]', input_string, flags=re.IGNORECASE)\n",
    "        # NATO\n",
    "        words='Alpha|Bravo|Charlie|Delta|Echo|Foxtrot|Golf|Hotel|India|Juliet|Kilo|Lima|Mike|\\\n",
    "                Oscar|Papa|Quebec|Romeo|Sierra|Tango|Uniform|Victor|Whisky|Yankee|Zulu'\n",
    "        input_string = re.sub(words,'[SDI_Redacted_military]', input_string, flags=re.IGNORECASE)\n",
    "        return input_string\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# (!!!) SET BEFORE RUNNING (!!!)\n",
    "# Folder of transcripts\n",
    "tsdir = '/Users/tejomay.gadgil/Downloads/redacted_transcript_landing'\n",
    "# Metadata file\n",
    "mddir = '/Users/tejomay.gadgil/Downloads/GRC Call Audio Metadata 2022-05-01 to 2022-05-28.xlsx - Case Extract.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c52de9d-44bc-47d2-aec2-6a07dd023eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(tsdir)\n",
    "ts = pd.DataFrame()\n",
    "errors = {}\n",
    "for file in flist:\n",
    "    floc = tsdir + '/' + file\n",
    "    try:\n",
    "        # Reads JSON\n",
    "        fjson = open(floc)\n",
    "        fjson = fjson.read()\n",
    "        fjson = json.loads(fjson)\n",
    "        # Grab transcripts, channelTag, and totalBilledTime\n",
    "        transcripts  = []\n",
    "        channel_tags = []\n",
    "        for result in fjson[\"results\"]:\n",
    "            transcripts.append(result[\"alternatives\"][0][\"transcript\"])\n",
    "            channel_tags.append(result[\"channelTag\"])\n",
    "        call_len_sec = fjson[\"totalBilledTime\"][:-1]\n",
    "        # Create _df for file\n",
    "        _df = pd.DataFrame({\"transcript\": transcripts, \n",
    "                            \"channel_tag\": channel_tags,\n",
    "                            \"call_len_sec\": call_len_sec})\n",
    "        _df.loc[:, 'file_name'] = file\n",
    "        _df.loc[:, 'line_number'] = _df.index\n",
    "        # Append to ts\n",
    "        ts = pd.concat([ts, _df])\n",
    "\n",
    "    except Exception as e:\n",
    "        errors[file] = e\n",
    "\n",
    "# Convert call_len_sec to numeric\n",
    "ts.loc[:, 'call_len_sec'] = ts.loc[:, 'call_len_sec'].astype(int)\n",
    "# Create call_ID\n",
    "ts['call_id'] = ts.loc[:, 'file_name'].map(lambda x: x[28:40])\n",
    "# Rearrange columns\n",
    "ts = ts.loc[:, ['call_id', 'call_len_sec', 'line_number', 'channel_tag', 'transcript']] \\\n",
    "       .reset_index(drop = True)\n",
    "# 7/29/2022 Redact\n",
    "ts['transcript'] = ts['transcript'].apply(SDI_redact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2986c5c5-fc86-4bf0-922b-0b20eb9341a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6/30/2022 Reformat \n",
    "ts_df = pd.DataFrame({'call_len_sec': ts.groupby('call_id')['call_len_sec'].first(),\n",
    "                      'transcript': ['. '.join(list(t)) for _, t in ts.groupby('call_id')['transcript']]})\n",
    "\n",
    "# 7/21/2022 Separate representative and customer transcripts\n",
    "ts_df = ts_df.join(ts[ts['channel_tag'] == 2].groupby('call_id')['transcript'].apply(lambda x: '. '.join(x)), rsuffix = '_rep') \\\n",
    "             .join(ts[ts['channel_tag'] == 1].groupby('call_id')['transcript'].apply(lambda x: '. '.join(x)), rsuffix = '_cus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d24e640-6237-483d-8c42-112c6f0b6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in metadata (https://docs.google.com/spreadsheets/d/1_zjEg2IhQkJCeIIAVGqdHiQ7qoFrODSl)\n",
    "md = pd.read_csv(mddir, dtype = str, parse_dates = ['CREATED_DATE_TIME'])\n",
    "# Create new 'weekday' variable that shows day of the week\n",
    "md['weekday'] = md['CREATED_DATE_TIME'].dt.weekday\n",
    "# Create 'transfer' flag\n",
    "md['transfer'] = md[\"CASE_TIER_2_US\"].str.contains(\"Transfer\", na=False)\n",
    "# Merge dataframes on CONTACT_ID\n",
    "ts_md = ts_df.join(md.set_index('CONTACT_ID').drop(columns = ['FILEPATH']))\n",
    "ts_md.index.name = 'call_id'\n",
    "# Join the columns of unstructured text\n",
    "ts_md['md_desc'] = ts_md['SUBJECT'] + '. ' + ts_md['DESCRIPTION']\n",
    "\n",
    "# Create `full_df`\n",
    "full_df = ts_md[['call_len_sec', 'CREATED_DATE_TIME', 'CONTACT_TYPE', 'OWNER_NAME_CURRENT',\n",
    "                 'IVR_REASON', 'INCONTACT_SKILL', 'PRODUCT_NAME', \n",
    "                 'CASE_TIER_1_GLOBAL', 'CASE_TIER_2_US', 'CASE_TIER_3_US', \n",
    "                 'DESCRIPTION', 'SUBJECT', 'md_desc', 'transfer', 'transcript', 'transcript_rep', 'transcript_cus']].copy()\n",
    "full_df['transcript'] = full_df['transcript'].astype(str)\n",
    "full_df['transcript_rep'] = full_df['transcript_rep'].astype(str)\n",
    "full_df['transcript_cus'] = full_df['transcript_cus'].astype(str)\n",
    "\n",
    "# Drop flags\n",
    "full_df['drop_testing_training'] = (full_df['IVR_REASON'] == 'Test and Training')\n",
    "full_df['drop_call_len_0'] = (full_df['call_len_sec'] == 0)\n",
    "full_df['drop_voicemail'] = (full_df['transcript'].str.find('person you have called') > -1) | (full_df['transcript'].str.find('record your message') > -1)\n",
    "\n",
    "# Create `dist` (ignore drop flags)\n",
    "dist = full_df.loc[~(full_df['drop_testing_training'] | full_df['drop_call_len_0'] | full_df['drop_voicemail']),\n",
    "                    ['call_len_sec', 'CREATED_DATE_TIME', 'CONTACT_TYPE',\n",
    "                     'IVR_REASON', 'INCONTACT_SKILL', 'PRODUCT_NAME', \n",
    "                     'CASE_TIER_1_GLOBAL', 'CASE_TIER_2_US', 'CASE_TIER_3_US',\n",
    "                     'transcript', 'md_desc']].copy()\n",
    "# Numeric columns\n",
    "dist['call_len_sec'] = dist['call_len_sec'].astype(int)\n",
    "dist['call_day']  = dist['CREATED_DATE_TIME'].dt.weekday\n",
    "dist['call_hour'] = dist['CREATED_DATE_TIME'].dt.hour       \n",
    "# Get inverse frequency from categorical columns\n",
    "dist_dict = {}\n",
    "for col in ['CONTACT_TYPE', 'IVR_REASON', 'INCONTACT_SKILL', 'PRODUCT_NAME', \n",
    "            'CASE_TIER_1_GLOBAL', 'CASE_TIER_2_US', 'CASE_TIER_3_US', 'call_day', 'call_hour']:\n",
    "    dist_dict[col] = (1 / dist[col].value_counts(normalize = True)).to_dict()\n",
    "    dist_dict[col][np.nan] = np.nan\n",
    "    dist[col] = [dist_dict[col][val] for val in dist[col]]\n",
    "dist.drop(columns = ['CREATED_DATE_TIME', 'transcript', 'md_desc'], inplace = True)\n",
    "# Get dist\n",
    "dist = dist.astype(float)\n",
    "dist = dist.fillna(dist.mean().to_dict()) # Impute\n",
    "dist = (dist - dist.mean()) / dist.std() # Normalize\n",
    "dist['dist'] = np.linalg.norm(dist, axis = 1) # Get distance\n",
    "\n",
    "# Merge back `dist`\n",
    "full_df['Call length'] = pd.cut(dist['call_len_sec'], \n",
    "                             [dist['call_len_sec'].min(), \n",
    "                              dist['call_len_sec'].median(), \n",
    "                              dist['call_len_sec'].max()], labels = ['Short', 'Long'])\n",
    "full_df['Call content'] = pd.cut(dist['dist'],\n",
    "                           [dist['dist'].min(), \n",
    "                            dist['dist'].median(), \n",
    "                            dist['dist'].max()], labels = ['Typical', 'Atypical'])\n",
    "# Export\n",
    "full_df.to_csv('df/full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3166ddb2-c20c-4180-9d0d-5e06ceb64ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['google_redactions'] = full_df['transcript'].str.count('##redacted##')\n",
    "\n",
    "full_df['SDI_Redacted_military'] = full_df['transcript'].str.count('SDI_Redacted_military')\n",
    "full_df['SDI_Redacted_names'] = full_df['transcript'].str.count('SDI_Redacted_names')\n",
    "full_df['SDI_Redacted_numbers'] = full_df['transcript'].str.count('SDI_Redacted_numbers')\n",
    "full_df['SDI_Redacted_states'] = full_df['transcript'].str.count('SDI_Redacted_states')\n",
    "full_df['SDI_Redacted_months'] = full_df['transcript'].str.count('SDI_Redacted_months')\n",
    "full_df['SDI_Redacted_ph_numbers'] = full_df['transcript'].str.count('SDI_Redacted_ph_numbers')\n",
    "\n",
    "full_df['SDI_redactions'] = full_df['SDI_Redacted_military'] + full_df['SDI_Redacted_names'] + full_df['SDI_Redacted_numbers'] +\\ \n",
    "full_df['SDI_Redacted_states'] + full_df['SDI_Redacted_months'] + full_df['SDI_Redacted_ph_numbers']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
